{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:27:43.341026Z",
     "start_time": "2023-04-10T11:27:43.274430Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "import geopandas as gpd\n",
    "config = dotenv_values(\".env\") #apikey\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Great Documentation can be found here: https://buildmedia.readthedocs.org/media/pdf/postgrest/v0.3.2/postgrest.pdf\n",
    "\n",
    "We start by register the Station data with the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:27:43.341790Z",
     "start_time": "2023-04-10T11:27:43.283129Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station = {\n",
    "    \"stationname\":\"sniffer\",\n",
    "    \"projectid\":\"SETx-UIFL Beaumont\",\n",
    "    \"description\": \"Beaumont Run of the SNIFFER air quality sensor for VOCUS data\",\n",
    "    \"contactname\": \"Pawell\",\n",
    "    \"contactemail\": \"Pawell@utexas.edu\",\n",
    "    \"active\":True,\n",
    "    \"startdate\": \"Feb 23, 2023 17:05:57\",\n",
    "    \"datetime\": \"Feb 25, 2023 12:18:11\"\n",
    "}\n",
    "# r = requests.post(\"https://postgrest-dev.proudflower-a6582e11.centralus.azurecontainerapps.io/station\", headers={'Authorization': f'Bearer {config[\"apikey\"]}',\n",
    "#          }, data=station)\n",
    "# print(r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can then  clean the sensor data. which requires us to load 4 datasets.\n",
    " - Mass list which will generate each measurements alias.\n",
    "- Sensor provides the 1d measurement data from the Sniffer\n",
    "- engdata provides the 1d engineering metadata from the sensor\n",
    "- engdataNames is the header file for the engdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:27:47.767069Z",
     "start_time": "2023-04-10T11:27:43.290028Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MassList = pd.read_csv(\"2023Beaumont_partial/w_data/Export/UL/IonList/MassIDs_2023.02.23-17h36m01sUL.csv\", header=None)\n",
    "sensor = np.fromfile(\"2023Beaumont_partial/w_data/Export/UL/CPS/cps2023.02.23-17h36m01sUL.fdt\", sep=\"\\n\")\n",
    "engData = np.fromfile(\"2023Beaumont_partial/w_data/Export/EngData/EngData2023.02.23-17h36m01s.fdt\",sep=\"\\n\")\n",
    "with open (\"2023Beaumont_partial/w_data/Export/EngData/EngDataNames2023.02.23-17h36m01s.csv\" , encoding=\"ISO-8859-1\") as f:\n",
    "    engDataNames = (f.read().split(\"\\n\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For the sensor data we need to add columns that are the same for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:27:47.773003Z",
     "start_time": "2023-04-10T11:27:47.771006Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sensor_table = pd.DataFrame({\"alias\":MassList[0].tolist()})\n",
    "sensor_table['postprocess']=True\n",
    "sensor_table['postprocessscript']=None\n",
    "sensor_table['units']='Counts Per Second'\n",
    "sensor_table['datatype']=1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For the Sensor data it is linked to a specific station. Which can be found by the project name SETx-UIFL. Below I'll make a request that filters out by SETx-UIFL and the the station Name sniffer.\n",
    "\n",
    "To use filters we will use the column name =eq.  and the the specific name\n",
    "ex :  projectid=eq.SETx-UIFL Beaumont\n",
    "\n",
    "\n",
    "the following operators are available:\n",
    "\n",
    "|  abbreviation |  meaning|\n",
    "|---------------|---------|\n",
    "|  eq | equals | \n",
    "|  gte | greater than or equal | \n",
    "| gt | greater than | \n",
    "| lte | less than or equal | \n",
    "| lt | less than | \n",
    "| neq | not equal | \n",
    "| like | LIKE operator (use * in place of %) | \n",
    "| ilike | ILIKE operator (use * in place of %) | \n",
    "| in | one of a list of values e.g. ?a=in.1,2,3 | \n",
    "| notin|  not one of a list of values e.g. ?a=notin.1,2,3 is checking for exact equality (null,true,false) | \n",
    "| isnot | checking for exact inequality (null,true,false) | \n",
    "| @@ | full-text search using to_tsquery | \n",
    "| @> | contains e.g. ?tags=@>.{example, new} <@ contained in e.g. values=<@{1,2,3} | \n",
    "| not | negates another operator, see below|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:27:54.386665Z",
     "start_time": "2023-04-10T11:27:47.775530Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# r = requests.get(\"https://postgrest-dev.proudflower-a6582e11.centralus.azurecontainerapps.io/station?projectid=eq.SETx-UIFL Beaumont&stationname=eq.sniffer\")\n",
    "# sensor_table['stationid']= r.json()[0]['stationid']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Then we can upload that sensor table into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:27:54.390629Z",
     "start_time": "2023-04-10T11:27:54.389425Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# r = requests.post(\"https://postgrest-dev.proudflower-a6582e11.centralus.azurecontainerapps.io/sensor\", headers={'Authorization': f'Bearer {config[\"apikey\"]}',\n",
    "#          'Content-Type':'text/csv'}, data=sensor_table.to_csv(header=True, index=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally we will transform the measurement data into a useable format and upload the data.\n",
    "\n",
    "We'll start by transforming the engData and measurement_df from 1-Dimensional to 2-dimensional. We skip the first three lines because they are the header to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:27:54.398031Z",
     "start_time": "2023-04-10T11:27:54.396470Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engData = pd.DataFrame(engData[3:].reshape(int(engData[1]),int(engData[2]), order='F' ), columns=engDataNames[:-1])\n",
    "measurement_df = pd.DataFrame(sensor[3:].reshape(int(sensor[2]), int(sensor[1])), columns=(MassList[0].tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We then create the collection time for each measurement. This is based on the engData JulianDate Column. Julian Date is the number of dates since Jan 01, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:27:54.404378Z",
     "start_time": "2023-04-10T11:27:54.398588Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engData['collectiontime']=(pd.to_datetime(pd.Timestamp('2009-01-01T00:00:00').to_julian_date()+engData['JulianDate'], unit='D',origin='julian'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:27:54.436412Z",
     "start_time": "2023-04-10T11:27:54.406453Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measurement_df=(pd.concat([engData, measurement_df], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:27:54.436591Z",
     "start_time": "2023-04-10T11:27:54.434455Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# measurement_df['elevation']=None\n",
    "# measurement_df['geometry']=None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The Last thing we'll need to add to the measurement is the GPS locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:27:54.605675Z",
     "start_time": "2023-04-10T11:27:54.439277Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Time_UTC            Time_CDT    Lat_deg   Lon_deg  \\\n",
      "33077  2023/02/23 22:49:00.000 2023-02-23 17:49:00  30.046037 -94.07243   \n",
      "33078  2023/02/23 22:49:01.000 2023-02-23 17:49:01  30.046037 -94.07243   \n",
      "33079  2023/02/23 22:49:02.000 2023-02-23 17:49:02  30.046037 -94.07243   \n",
      "33080  2023/02/23 22:49:03.000 2023-02-23 17:49:03  30.046037 -94.07243   \n",
      "33081  2023/02/23 22:49:04.000 2023-02-23 17:49:04  30.046037 -94.07243   \n",
      "33082  2023/02/23 22:49:05.000 2023-02-23 17:49:05  30.046037 -94.07243   \n",
      "33083  2023/02/23 22:49:06.000 2023-02-23 17:49:06  30.046037 -94.07243   \n",
      "33084  2023/02/23 22:49:07.000 2023-02-23 17:49:07  30.046037 -94.07243   \n",
      "33085  2023/02/23 22:49:08.000 2023-02-23 17:49:08  30.046037 -94.07243   \n",
      "33086  2023/02/23 22:49:09.000 2023-02-23 17:49:09  30.046037 -94.07243   \n",
      "33087  2023/02/23 22:49:10.000 2023-02-23 17:49:10  30.046037 -94.07243   \n",
      "33088  2023/02/23 22:49:11.000 2023-02-23 17:49:11  30.046037 -94.07243   \n",
      "33089  2023/02/23 22:49:12.000 2023-02-23 17:49:12  30.046037 -94.07243   \n",
      "33090  2023/02/23 22:49:13.000 2023-02-23 17:49:13  30.046037 -94.07243   \n",
      "33091  2023/02/23 22:49:14.000 2023-02-23 17:49:14  30.046037 -94.07243   \n",
      "33092  2023/02/23 22:49:16.000 2023-02-23 17:49:16  30.046037 -94.07243   \n",
      "33093  2023/02/23 22:49:17.000 2023-02-23 17:49:17  30.046037 -94.07243   \n",
      "33094  2023/02/23 22:49:18.000 2023-02-23 17:49:18  30.046037 -94.07243   \n",
      "33095  2023/02/23 22:49:18.000 2023-02-23 17:49:18  30.046037 -94.07243   \n",
      "33096  2023/02/23 22:49:19.000 2023-02-23 17:49:19  30.046037 -94.07243   \n",
      "33097  2023/02/23 22:49:20.000 2023-02-23 17:49:20  30.046037 -94.07243   \n",
      "33098  2023/02/23 22:49:21.000 2023-02-23 17:49:21  30.046037 -94.07243   \n",
      "33099  2023/02/23 22:49:23.000 2023-02-23 17:49:23  30.046037 -94.07243   \n",
      "33100  2023/02/23 22:49:24.000 2023-02-23 17:49:24  30.046037 -94.07243   \n",
      "33101  2023/02/23 22:49:24.000 2023-02-23 17:49:24  30.046037 -94.07243   \n",
      "33102  2023/02/23 22:49:25.000 2023-02-23 17:49:25  30.046037 -94.07243   \n",
      "33103  2023/02/23 22:49:26.000 2023-02-23 17:49:26  30.046037 -94.07243   \n",
      "33104  2023/02/23 22:49:27.000 2023-02-23 17:49:27  30.046037 -94.07243   \n",
      "33105  2023/02/23 22:49:28.000 2023-02-23 17:49:28  30.046037 -94.07243   \n",
      "33106  2023/02/23 22:49:30.000 2023-02-23 17:49:30  30.046037 -94.07243   \n",
      "33107  2023/02/23 22:49:30.000 2023-02-23 17:49:30  30.046037 -94.07243   \n",
      "33108  2023/02/23 22:49:32.000 2023-02-23 17:49:32  30.046037 -94.07243   \n",
      "33109  2023/02/23 22:49:33.000 2023-02-23 17:49:33  30.046037 -94.07243   \n",
      "33110  2023/02/23 22:49:34.000 2023-02-23 17:49:34  30.046037 -94.07243   \n",
      "33111  2023/02/23 22:49:35.000 2023-02-23 17:49:35  30.046037 -94.07243   \n",
      "33112  2023/02/23 22:49:36.000 2023-02-23 17:49:36  30.046037 -94.07243   \n",
      "33113  2023/02/23 22:49:36.000 2023-02-23 17:49:36  30.046037 -94.07243   \n",
      "33114  2023/02/23 22:49:38.000 2023-02-23 17:49:38  30.046037 -94.07243   \n",
      "33115  2023/02/23 22:49:39.000 2023-02-23 17:49:39  30.046037 -94.07243   \n",
      "33116  2023/02/23 22:49:40.000 2023-02-23 17:49:40  30.046037 -94.07243   \n",
      "33117  2023/02/23 22:49:41.000 2023-02-23 17:49:41  30.046037 -94.07243   \n",
      "33118  2023/02/23 22:49:42.000 2023-02-23 17:49:42  30.046037 -94.07243   \n",
      "33119  2023/02/23 22:49:43.000 2023-02-23 17:49:43  30.046037 -94.07243   \n",
      "33120  2023/02/23 22:49:44.000 2023-02-23 17:49:44  30.046037 -94.07243   \n",
      "33121  2023/02/23 22:49:45.000 2023-02-23 17:49:45  30.046037 -94.07243   \n",
      "33122  2023/02/23 22:49:46.000 2023-02-23 17:49:46  30.046037 -94.07243   \n",
      "33123  2023/02/23 22:49:47.000 2023-02-23 17:49:47  30.046037 -94.07243   \n",
      "33124  2023/02/23 22:49:48.000 2023-02-23 17:49:48  30.046037 -94.07243   \n",
      "33125  2023/02/23 22:49:49.000 2023-02-23 17:49:49  30.046037 -94.07243   \n",
      "33126  2023/02/23 22:49:50.000 2023-02-23 17:49:50  30.046037 -94.07243   \n",
      "33127  2023/02/23 22:49:51.000 2023-02-23 17:49:51  30.046037 -94.07243   \n",
      "33128  2023/02/23 22:49:52.000 2023-02-23 17:49:52  30.046037 -94.07243   \n",
      "33129  2023/02/23 22:49:53.000 2023-02-23 17:49:53  30.046037 -94.07243   \n",
      "33130  2023/02/23 22:49:54.000 2023-02-23 17:49:54  30.046037 -94.07243   \n",
      "33131  2023/02/23 22:49:55.000 2023-02-23 17:49:55  30.046037 -94.07243   \n",
      "33132  2023/02/23 22:49:56.000 2023-02-23 17:49:56  30.046037 -94.07243   \n",
      "33133  2023/02/23 22:49:57.000 2023-02-23 17:49:57  30.046037 -94.07243   \n",
      "33134  2023/02/23 22:49:58.000 2023-02-23 17:49:58  30.046037 -94.07243   \n",
      "33135  2023/02/23 22:49:59.000 2023-02-23 17:49:59  30.046037 -94.07243   \n",
      "\n",
      "       Speed_km_h  Speed m_s  Heading_deg  \n",
      "33077     0.01852   0.005144       241.73  \n",
      "33078     0.01852   0.005144       241.73  \n",
      "33079     0.03704   0.010289       241.73  \n",
      "33080     0.03704   0.010289       241.73  \n",
      "33081     0.01852   0.005144       241.73  \n",
      "33082     0.01852   0.005144       241.73  \n",
      "33083     0.01852   0.005144       241.73  \n",
      "33084     0.01852   0.005144       241.73  \n",
      "33085     0.01852   0.005144       241.73  \n",
      "33086     0.03704   0.010289       241.73  \n",
      "33087     0.03704   0.010289       241.73  \n",
      "33088     0.07408   0.020578       241.73  \n",
      "33089     0.03704   0.010289       241.73  \n",
      "33090     0.03704   0.010289       241.73  \n",
      "33091     0.03704   0.010289       241.73  \n",
      "33092     0.00000   0.000000       241.73  \n",
      "33093     0.00000   0.000000       241.73  \n",
      "33094     0.00000   0.000000       241.73  \n",
      "33095     0.00000   0.000000       241.73  \n",
      "33096     0.01852   0.005144       241.73  \n",
      "33097     0.03704   0.010289       241.73  \n",
      "33098     0.03704   0.010289       241.73  \n",
      "33099     0.01852   0.005144       241.73  \n",
      "33100     0.01852   0.005144       241.73  \n",
      "33101     0.01852   0.005144       241.73  \n",
      "33102     0.03704   0.010289       241.73  \n",
      "33103     0.03704   0.010289       241.73  \n",
      "33104     0.05556   0.015433       241.73  \n",
      "33105     0.01852   0.005144       241.73  \n",
      "33106     0.03704   0.010289       241.73  \n",
      "33107     0.03704   0.010289       241.73  \n",
      "33108     0.03704   0.010289       241.73  \n",
      "33109     0.01852   0.005144       241.73  \n",
      "33110     0.01852   0.005144       241.73  \n",
      "33111     0.01852   0.005144       241.73  \n",
      "33112     0.03704   0.010289       241.73  \n",
      "33113     0.03704   0.010289       241.73  \n",
      "33114     0.01852   0.005144       241.73  \n",
      "33115     0.03704   0.010289       241.73  \n",
      "33116     0.03704   0.010289       241.73  \n",
      "33117     0.05556   0.015433       241.73  \n",
      "33118     0.07408   0.020578       241.73  \n",
      "33119     0.01852   0.005144       241.73  \n",
      "33120     0.07408   0.020578       241.73  \n",
      "33121     0.03704   0.010289       241.73  \n",
      "33122     0.07408   0.020578       241.73  \n",
      "33123     0.01852   0.005144       241.73  \n",
      "33124     0.01852   0.005144       241.73  \n",
      "33125     0.01852   0.005144       241.73  \n",
      "33126     0.00000   0.000000       241.73  \n",
      "33127     0.05556   0.015433       241.73  \n",
      "33128     0.03704   0.010289       241.73  \n",
      "33129     0.03704   0.010289       241.73  \n",
      "33130     0.03704   0.010289       241.73  \n",
      "33131     0.07408   0.020578       241.73  \n",
      "33132     0.05556   0.015433       241.73  \n",
      "33133     0.05556   0.015433       241.73  \n",
      "33134     0.03704   0.010289       241.73  \n",
      "33135     0.01852   0.005144       241.73  \n"
     ]
    }
   ],
   "source": [
    "gps = pd.read_csv(\"2023Beaumont_partial/Beaumont2023FebMarchOutputGPS.txt\")\n",
    "gps['Time_CDT']=(pd.to_datetime(gps['Time_CDT']))\n",
    "print(gps.loc[(gps['Time_CDT'].dt.month==2) & (gps['Time_CDT'].dt.day==23) & (gps['Time_CDT'].dt.hour==17)& (gps['Time_CDT'].dt.minute==49) ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can see there will be a mismatch between the time GPS data is collected and sensor data. So have a few steps to clean the data before we can link the GPS and measurement data:\n",
    "  - Use the get point at Distance to interpolate the new lat long.\n",
    "    - We need to convert Speed m_s to km_s and then calculate the distance as delta between time gps and sensor.\n",
    "    - *Code from: https://stackoverflow.com/questions/7222382/get-lat-long-given-current-point-distance-and-bearing*\n",
    "- convert the GPS dataframe to Geopandas dataframe and a geometry point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:27:54.610575Z",
     "start_time": "2023-04-10T11:27:54.609514Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import asin, atan2, cos, degrees, radians, sin\n",
    "\n",
    "def get_point_at_distance(lat1, lon1, d, bearing, R=6371):\n",
    "    \"\"\" https://stackoverflow.com/questions/7222382/get-lat-long-given-current-point-distance-and-bearing\n",
    "    lat: initial latitude, in degrees\n",
    "    lon: initial longitude, in degrees\n",
    "    d: target distance from initial\n",
    "    bearing: (true) heading in degrees\n",
    "    R: optional radius of sphere, defaults to mean radius of earth\n",
    "\n",
    "    Returns new lat/lon coordinate {d}km from initial, in degrees\n",
    "    \"\"\"\n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)\n",
    "    a = radians(bearing)\n",
    "    lat2 = asin(sin(lat1) * cos(d/R) + cos(lat1) * sin(d/R) * cos(a))\n",
    "    lon2 = lon1 + atan2(\n",
    "        sin(a) * sin(d/R) * cos(lat1),\n",
    "        cos(d/R) - sin(lat1) * sin(lat2)\n",
    "    )\n",
    "    return (degrees(lat2), degrees(lon2),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:34:08.132606Z",
     "start_time": "2023-04-10T11:34:08.126713Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_lat_long(t):\n",
    "    subset = gps.loc[(gps['Time_CDT'].dt.year==t.year) & (gps['Time_CDT'].dt.month==t.month) & (gps['Time_CDT'].dt.day==t.day)\n",
    " & (gps['Time_CDT'].dt.hour==t.hour)& (gps['Time_CDT'].dt.minute==t.minute)& (gps['Time_CDT'].dt.second==t.second), ]\n",
    "    try:\n",
    "        delta = (t.microsecond - subset['Time_CDT'].dt.microsecond.to_list()[0]) * .000001\n",
    "\n",
    "        lat = subset['Lat_deg'].to_list()[0]\n",
    "        long = subset['Lon_deg'].to_list()[0]\n",
    "        degree = subset['Heading_deg'].to_list()[0]\n",
    "        distance = delta * subset['Speed m_s'].to_list()[0]\n",
    "    except:\n",
    "        subset = gps.loc[(gps['Time_CDT'].dt.year==t.year) & (gps['Time_CDT'].dt.month==t.month) & (gps['Time_CDT'].dt.day==t.day)\n",
    " & (gps['Time_CDT'].dt.hour==t.hour)& (gps['Time_CDT'].dt.minute==t.minute)& (gps['Time_CDT'].dt.second==t.second-1), ]\n",
    "        delta = (t.microsecond - subset['Time_CDT'].dt.microsecond.to_list()[0]) * .000001\n",
    "\n",
    "        lat = subset['Lat_deg'].to_list()[0]\n",
    "        long = subset['Lon_deg'].to_list()[0]\n",
    "        degree = subset['Heading_deg'].to_list()[0]\n",
    "        distance = delta * subset['Speed m_s'].to_list()[0]\n",
    "    lat, long = get_point_at_distance(lat, long, distance, degree)\n",
    "    return  f'POINT({lat} {long})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:34:28.371355Z",
     "start_time": "2023-04-10T11:34:08.430445Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measurement_df['geometry']=measurement_df['collectiontime'].apply(lambda row: calculate_lat_long(row) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T11:34:28.378123Z",
     "start_time": "2023-04-10T11:34:28.374915Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        POINT(30.046026491635423 -94.0731252314149)\n",
      "1       POINT(30.023292515520765 -94.06698123834101)\n",
      "2       POINT(30.025708174510278 -94.06359943652627)\n",
      "3       POINT(30.045600328479882 -94.07271915374736)\n",
      "4       POINT(30.028833898418693 -94.06001808846878)\n",
      "                            ...                     \n",
      "1795     POINT(30.00728179898451 -94.03820809236207)\n",
      "1796    POINT(30.012291644596665 -94.04249124627863)\n",
      "1797    POINT(30.009754937238696 -94.03976809505963)\n",
      "1798     POINT(30.01439183827795 -94.04449054528398)\n",
      "1799     POINT(30.01094466023334 -94.04086961772742)\n",
      "Name: geometry, Length: 1800, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(measurement_df['geometry'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We'll need to get the appropriate sensorid for each measurement group. Make a subset table and upload that as a measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_df.to_csv('measurement2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T13:12:45.707203Z",
     "start_time": "2023-04-10T11:43:49.936243Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.3623\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# r = requests.get(f\"https://postgrest-dev.proudflower-a6582e11.centralus.azurecontainerapps.io/sensor?alias=eq.{m}\")\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m measurement_df[\u001b[39m\"\u001b[39m\u001b[39msensorid\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m=\u001b[39mr\u001b[39m.\u001b[39mjson()[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msensorid\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m measurement_df[\u001b[39m'\u001b[39m\u001b[39mmeasurementvalue\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mmeasurement_df[m]\n\u001b[1;32m      7\u001b[0m data \u001b[39m=\u001b[39m measurement_df[[\u001b[39m'\u001b[39m\u001b[39msensorid\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcollectiontime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m,  \u001b[39m'\u001b[39m\u001b[39mmeasurementvalue\u001b[39m\u001b[39m'\u001b[39m ]]\u001b[39m.\u001b[39mto_csv(header\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "for m in MassList[0].tolist():\n",
    "    print(m)\n",
    "\n",
    "    # r = requests.get(f\"https://postgrest-dev.proudflower-a6582e11.centralus.azurecontainerapps.io/sensor?alias=eq.{m}\")\n",
    "    # measurement_df[\"sensorid\"]=r.json()[0]['sensorid']\n",
    "    measurement_df['measurementvalue']=measurement_df[m]\n",
    "    data = measurement_df[['sensorid','collectiontime', 'geometry',  'measurementvalue' ]].to_csv(header=True, index=False)\n",
    "    # r=requests.post(\"https://postgrest-dev.proudflower-a6582e11.centralus.azurecontainerapps.io/measurement\", headers={'Authorization': f'Bearer {config[\"apikey\"]}',\n",
    "        #  'Content-Type':'text/csv'}, data=data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T15:36:08.751088Z",
     "start_time": "2023-04-05T15:36:08.739411Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
